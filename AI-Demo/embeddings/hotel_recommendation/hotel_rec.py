import pandas as pd
from sklearn.metrics.pairwise import linear_kernel  # â†’ è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
import re
import matplotlib.pyplot as plt
import os
from constants import ENGLISH_STOPWORDS

pd.options.display.max_columns = 30

# æ”¯æŒä¸­æ–‡
plt.rcParams["font.sans-serif"] = ["SimHei"]  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾

# è¯»å–æ•°æ® + æ¢ç´¢
base_dir = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(base_dir, "Seattle_Hotels.csv")
df = pd.read_csv(csv_path, encoding="latin-1")

print(df.head())
print("æ•°æ®é›†ä¸­çš„é…’åº—ä¸ªæ•°ï¼š", len(df))

def print_description(index):
    example = df[df.index == index][["desc", "name"]].values[0]
    if len(example) > 0:
        print(example[0])
        print("Name:", example[1])


print("ç¬¬10ä¸ªé…’åº—çš„æè¿°ï¼š")
print_description(10)


# å¾—åˆ°é…’åº—æè¿°ä¸­n-gramç‰¹å¾ä¸­çš„TopKä¸ª
def get_top_n_words(corpus, n=1, k=None):
    # ç»Ÿè®¡ngramè¯é¢‘çŸ©é˜µï¼Œä½¿ç”¨è‡ªå®šä¹‰åœç”¨è¯åˆ—è¡¨ â†’ è¯é¢‘ç»Ÿè®¡
    vec = CountVectorizer(ngram_range=(n, n), stop_words=list(ENGLISH_STOPWORDS)).fit(
        corpus
    )
    bag_of_words = vec.transform(corpus)
    """
    print('feature names:')
    print(vec.get_feature_names())
    print('bag of words:')
    print(bag_of_words.toarray())
    """
    sum_words = bag_of_words.sum(axis=0)
    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    print(f"{words_freq} <<< n-gram åœ¨æ‰€æœ‰é…’åº—æè¿°ä¸­å‡ºç°çš„æ¬¡æ•°")
    # æŒ‰ç…§è¯é¢‘ä»å¤§åˆ°å°æ’åº
    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)
    return words_freq[:k]


common_words = get_top_n_words(df["desc"], n=3, k=20)
print(common_words)


df1 = pd.DataFrame(common_words, columns=["desc", "count"])
df1.groupby("desc").sum()["count"].sort_values().plot(
    kind="barh", title="å»æ‰åœç”¨è¯åï¼Œé…’åº—æè¿°ä¸­çš„Top20å•è¯"
)

# plt.show() ğŸ‘‰ğŸ» å¯è§†åŒ–

# æ–‡æœ¬é¢„å¤„ç†
REPLACE_BY_SPACE_RE = re.compile(r"[/(){}\[\]\|@,;]")
BAD_SYMBOLS_RE = re.compile("[^0-9a-z #+_]")
# ä½¿ç”¨è‡ªå®šä¹‰çš„è‹±æ–‡åœç”¨è¯åˆ—è¡¨æ›¿ä»£nltkçš„stopwords
STOPWORDS = ENGLISH_STOPWORDS


# å¯¹æ–‡æœ¬è¿›è¡Œæ¸…æ´—
def clean_text(text):
    # å…¨éƒ¨å°å†™
    text = text.lower()
    # ç”¨ç©ºæ ¼æ›¿ä»£ä¸€äº›ç‰¹æ®Šç¬¦å·ï¼Œå¦‚æ ‡ç‚¹
    text = REPLACE_BY_SPACE_RE.sub(" ", text)
    # ç§»é™¤BAD_SYMBOLS_RE
    text = BAD_SYMBOLS_RE.sub("", text)
    # ä»æ–‡æœ¬ä¸­å»æ‰åœç”¨è¯
    text = " ".join(word for word in text.split() if word not in STOPWORDS)
    return text


# å¯¹descå­—æ®µè¿›è¡Œæ¸…ç†ï¼Œapplyé’ˆå¯¹æŸåˆ—
df["desc_clean"] = df["desc"].apply(clean_text)
# print(df['desc_clean'])

# å»ºæ¨¡
df.set_index("name", inplace=True)
# ä½¿ç”¨TF-IDFæå–æ–‡æœ¬ç‰¹å¾ï¼Œä½¿ç”¨è‡ªå®šä¹‰åœç”¨è¯åˆ—è¡¨
tf = TfidfVectorizer(
    analyzer="word", ngram_range=(1, 3), min_df=0.01, stop_words=list[str](ENGLISH_STOPWORDS)
)
# é’ˆå¯¹desc_cleanæå–tfidf
tfidf_matrix = tf.fit_transform(df["desc_clean"])
print("TFIDF feature names:")
# print(tf.get_feature_names_out())
print(len(tf.get_feature_names_out()))
print('tfidf_matrix:', tfidf_matrix)
print(tfidf_matrix.shape)
# è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆçº¿æ€§æ ¸å‡½æ•°ï¼‰
cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)
# print(cosine_similarities)
print(cosine_similarities.shape)
indices = pd.Series(df.index)  # df.indexæ˜¯é…’åº—åç§°


# åŸºäºç›¸ä¼¼åº¦çŸ©é˜µå’ŒæŒ‡å®šçš„é…’åº—nameï¼Œæ¨èTOP10é…’åº—
def recommendations(name, cosine_similarities=cosine_similarities):
    recommended_hotels = []
    # æ‰¾åˆ°æƒ³è¦æŸ¥è¯¢é…’åº—åç§°çš„idx
    idx = indices[indices == name].index[0]
    print("idx=", idx)
    # å¯¹äºidxé…’åº—çš„ä½™å¼¦ç›¸ä¼¼åº¦å‘é‡æŒ‰ç…§ä»å¤§åˆ°å°è¿›è¡Œæ’åº
    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)
    # å–ç›¸ä¼¼åº¦æœ€å¤§çš„å‰10ä¸ªï¼ˆé™¤äº†è‡ªå·±ä»¥å¤–ï¼‰
    top_10_indexes = list(score_series.iloc[1:11].index)
    # æ”¾åˆ°æ¨èåˆ—è¡¨ä¸­
    for i in top_10_indexes:
        recommended_hotels.append(list(df.index)[i])
    return recommended_hotels


print(recommendations("Hilton Seattle Airport & Conference Center"))
print(recommendations("The Bacon Mansion Bed and Breakfast"))
